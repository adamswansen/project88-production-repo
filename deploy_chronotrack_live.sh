#!/bin/bash

# ChronoTrack Live Integration - Production Deployment Script
# Project88Hub - Deploy to Production

set -e  # Exit on any error

# Add PostgreSQL to PATH (for macOS with Homebrew)
export PATH="/opt/homebrew/opt/postgresql@14/bin:$PATH"

# Configuration
DB_HOST="localhost"
DB_NAME="project88_myappdb"
DB_USER="project88_myappuser"
DB_PASSWORD="puctuq-cefwyq-3boqRe"
DB_PORT="5432"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Logging function
log() {
    echo -e "${BLUE}[$(date '+%Y-%m-%d %H:%M:%S')]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

# Check prerequisites
check_prerequisites() {
    log "ðŸ” Checking prerequisites..."
    
    # Check if psql is available
    if ! command -v psql &> /dev/null; then
        error "psql is not installed. Please install PostgreSQL client."
    fi
    
    # Check if Python 3 is available
    if ! command -v python3 &> /dev/null; then
        error "Python 3 is not installed."
    fi
    
    # Check if required Python packages are installed
    python3 -c "import psycopg2, requests, hashlib" 2>/dev/null || error "Required Python packages not installed. Run: pip install psycopg2-binary requests"
    
    # Test database connection
    if ! PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "SELECT 1;" &> /dev/null; then
        error "Cannot connect to database. Please check credentials."
    fi
    
    success "Prerequisites check passed"
}

# Backup current database schema
backup_database() {
    log "ðŸ“¦ Creating database backup..."
    
    backup_file="chronotrack_live_backup_$(date +%Y%m%d_%H%M%S).sql"
    
    PGPASSWORD=$DB_PASSWORD pg_dump -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME \
        --schema-only \
        --table=ct_events \
        --table=ct_participants \
        --table=ct_results \
        --table=providers \
        --table=partner_provider_credentials \
        > $backup_file
    
    if [ $? -eq 0 ]; then
        success "Database backup created: $backup_file"
    else
        error "Failed to create database backup"
    fi
}

# Deploy database schema
deploy_database_schema() {
    log "ðŸ—ï¸  Deploying database schema extension..."
    
    # Check if schema extension already applied
    schema_applied=$(PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -t -c "
        SELECT COUNT(*) FROM information_schema.columns 
        WHERE table_name = 'ct_events' AND column_name = 'data_source'
    " | tr -d ' ')
    
    if [ "$schema_applied" -eq "0" ]; then
        log "Applying database schema extension..."
        
        PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -f database/chronotrack_live_schema_extension.sql
        
        if [ $? -eq 0 ]; then
            success "Database schema extension applied successfully"
        else
            error "Failed to apply database schema extension"
        fi
    else
        success "Database schema extension already applied"
    fi
}

# Run comprehensive tests
run_tests() {
    log "ðŸ§ª Running comprehensive integration tests..."
    
    # Run tests in dry-run mode first
    python3 test_chronotrack_live_integration.py --dry-run --verbose
    
    if [ $? -eq 0 ]; then
        success "Integration tests passed"
    else
        error "Integration tests failed"
    fi
}

# Deploy credentials setup
deploy_credentials() {
    log "ðŸ” Setting up credentials..."
    
    # Check if ChronoTrack Live provider exists
    provider_exists=$(PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -t -c "
        SELECT COUNT(*) FROM providers WHERE provider_id = 1 AND name = 'ChronoTrack Live'
    " | tr -d ' ')
    
    if [ "$provider_exists" -eq "0" ]; then
        log "Creating ChronoTrack Live provider entry..."
        
        PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "
            INSERT INTO providers (provider_id, name, description, created_at)
            VALUES (1, 'ChronoTrack Live', 'ChronoTrack Live API Integration', NOW())
            ON CONFLICT (provider_id) DO UPDATE SET
                name = EXCLUDED.name,
                description = EXCLUDED.description;
        "
        
        if [ $? -eq 0 ]; then
            success "ChronoTrack Live provider created"
        else
            error "Failed to create ChronoTrack Live provider"
        fi
    else
        success "ChronoTrack Live provider already exists"
    fi
    
    # Show credentials status
    log "ðŸ“Š Current credentials status:"
    PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "
        SELECT 
            tp.timing_partner_id,
            tp.company_name,
            CASE 
                WHEN ppc.principal IS NOT NULL THEN 'SET'
                ELSE 'NOT SET'
            END as username_status,
            CASE 
                WHEN ppc.secret IS NOT NULL THEN 'SET'
                ELSE 'NOT SET'
            END as password_status
        FROM timing_partners tp
        LEFT JOIN partner_provider_credentials ppc ON tp.timing_partner_id = ppc.timing_partner_id AND ppc.provider_id = 1
        ORDER BY tp.timing_partner_id;
    "
}

# Install Python dependencies
install_dependencies() {
    log "ðŸ“¦ Installing Python dependencies..."
    
    # Create requirements.txt if it doesn't exist
    if [ ! -f "requirements.txt" ]; then
        cat > requirements.txt << EOF
psycopg2-binary>=2.8.6
requests>=2.25.1
python-dateutil>=2.8.2
EOF
    fi
    
    # Install dependencies
    python3 -m pip install -r requirements.txt
    
    if [ $? -eq 0 ]; then
        success "Dependencies installed successfully"
    else
        error "Failed to install dependencies"
    fi
}

# Create systemd service files
create_systemd_services() {
    log "ðŸ”§ Creating systemd service files..."
    
    # Create scheduler service
    cat > /tmp/chronotrack-live-scheduler.service << EOF
[Unit]
Description=ChronoTrack Live Scheduler
After=network.target postgresql.service

[Service]
Type=simple
User=project88
WorkingDirectory=/home/project88/Project88
ExecStart=/usr/bin/python3 schedulers/chronotrack_live_scheduler.py
Restart=always
RestartSec=10
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
EOF
    
    success "Systemd service files created in /tmp/"
    warning "To install services, run as root:"
    warning "sudo cp /tmp/chronotrack-live-scheduler.service /etc/systemd/system/"
    warning "sudo systemctl daemon-reload"
    warning "sudo systemctl enable chronotrack-live-scheduler.service"
}

# Create monitoring script
create_monitoring_script() {
    log "ðŸ“Š Creating monitoring script..."
    
    cat > monitor_chronotrack_live.py << 'EOF'
#!/usr/bin/env python3
"""
ChronoTrack Live Monitoring Script
Monitors integration health and provides status reports
"""

import psycopg2
import json
from datetime import datetime, timedelta

def check_integration_health():
    """Check ChronoTrack Live integration health"""
    db_config = {
        'host': 'localhost',
        'database': 'project88_myappdb',
        'user': 'project88_myappuser', 
        'password': 'puctuq-cefwyq-3boqRe',
        'port': 5432
    }
    
    try:
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor()
        
        # Check recent ChronoTrack Live events
        cursor.execute("""
            SELECT COUNT(*) FROM ct_events 
            WHERE data_source = 'chronotrack_live' 
            AND created_at >= NOW() - INTERVAL '24 hours'
        """)
        recent_events = cursor.fetchone()[0]
        
        # Check recent participants
        cursor.execute("""
            SELECT COUNT(*) FROM ct_participants 
            WHERE data_source = 'chronotrack_live' 
            AND created_at >= NOW() - INTERVAL '24 hours'
        """)
        recent_participants = cursor.fetchone()[0]
        
        # Check recent results
        cursor.execute("""
            SELECT COUNT(*) FROM ct_results 
            WHERE data_source = 'chronotrack_live' 
            AND created_at >= NOW() - INTERVAL '24 hours'
        """)
        recent_results = cursor.fetchone()[0]
        
        # Check credentials status
        cursor.execute("""
            SELECT COUNT(*) FROM partner_provider_credentials 
            WHERE provider_id = 1 AND principal IS NOT NULL AND secret IS NOT NULL
        """)
        active_credentials = cursor.fetchone()[0]
        
        conn.close()
        
        # Generate report
        report = {
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'metrics': {
                'recent_events_24h': recent_events,
                'recent_participants_24h': recent_participants,
                'recent_results_24h': recent_results,
                'active_timing_partners': active_credentials
            }
        }
        
        print(json.dumps(report, indent=2))
        
    except Exception as e:
        error_report = {
            'status': 'error',
            'timestamp': datetime.now().isoformat(),
            'error': str(e)
        }
        print(json.dumps(error_report, indent=2))

if __name__ == "__main__":
    check_integration_health()
EOF
    
    chmod +x monitor_chronotrack_live.py
    success "Monitoring script created: monitor_chronotrack_live.py"
}

# Main deployment function
main() {
    log "ðŸš€ Starting ChronoTrack Live Production Deployment"
    log "=================================================="
    
    # Run deployment steps
    check_prerequisites
    backup_database
    install_dependencies
    deploy_database_schema
    deploy_credentials
    run_tests
    create_systemd_services
    create_monitoring_script
    
    log "=================================================="
    success "ðŸŽ‰ ChronoTrack Live deployment completed successfully!"
    log ""
    log "Next steps:"
    log "1. Set up actual ChronoTrack Live credentials:"
    log "   - Get credentials from timing partners"
    log "   - Encode passwords: python3 -c \"import hashlib; print(hashlib.sha256('password'.encode()).hexdigest())\""
    log "   - Update database using: database/chronotrack_live_credentials_setup.sql"
    log ""
    log "2. Test with real credentials:"
    log "   python3 test_chronotrack_live_integration.py --timing-partner-id 1 --verbose"
    log ""
    log "3. Run initial backfill (be careful!):"
    log "   python3 backfill/chronotrack_live_backfill.py --dry-run --limit-events 10"
    log ""
    log "4. Start the scheduler:"
    log "   python3 schedulers/chronotrack_live_scheduler.py"
    log ""
    log "5. Monitor integration health:"
    log "   python3 monitor_chronotrack_live.py"
    log ""
    log "ðŸ”§ Integration Status: 14 providers (93% business requirements complete)"
}

# Run main deployment
main "$@" 